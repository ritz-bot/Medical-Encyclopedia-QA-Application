2025-08-11 13:57:45,270 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 13:57:45,270 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 13:58:06,110 - INFO - 127.0.0.1 - - [11/Aug/2025 13:58:06] "GET / HTTP/1.1" 200 -
2025-08-11 13:58:06,294 - INFO - 127.0.0.1 - - [11/Aug/2025 13:58:06] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-11 13:58:12,653 - INFO - Loading vector store for context
2025-08-11 13:58:12,653 - INFO - Initializing our Huggingface embedding model
2025-08-11 13:58:12,870 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 13:58:17,317 - INFO - Use pytorch device_name: mps
2025-08-11 13:58:17,318 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 13:58:19,405 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 13:58:19,407 - WARNING - No vectore store found..
2025-08-11 13:58:19,407 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-11 13:58:19,410 - INFO - 127.0.0.1 - - [11/Aug/2025 13:58:19] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 13:58:19,417 - INFO - 127.0.0.1 - - [11/Aug/2025 13:58:19] "GET / HTTP/1.1" 200 -
2025-08-11 14:06:15,329 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 14:06:15,329 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 14:06:19,666 - INFO - 127.0.0.1 - - [11/Aug/2025 14:06:19] "GET / HTTP/1.1" 200 -
2025-08-11 14:06:28,897 - INFO - Loading vector store for context
2025-08-11 14:06:28,898 - INFO - Current working directory: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app
2025-08-11 14:06:28,898 - INFO - Script location: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components
2025-08-11 14:06:28,898 - INFO - Expected vector store path: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/vectorstore
2025-08-11 14:06:28,898 - INFO - Vector store folder exists. Contents: ['db_faiss']
2025-08-11 14:06:28,898 - INFO - Initializing our Huggingface embedding model
2025-08-11 14:06:29,086 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 14:06:32,732 - INFO - Use pytorch device_name: mps
2025-08-11 14:06:32,732 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 14:06:34,651 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 14:06:34,651 - WARNING - No vectore store found..
2025-08-11 14:06:34,651 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 110
2025-08-11 14:06:34,653 - INFO - 127.0.0.1 - - [11/Aug/2025 14:06:34] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 14:06:34,659 - INFO - 127.0.0.1 - - [11/Aug/2025 14:06:34] "GET / HTTP/1.1" 200 -
2025-08-11 20:28:06,521 - INFO - MAking the vectorstore....
2025-08-11 20:28:06,522 - ERROR - Failed to load PDF | Error: Data path doesn't exist | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 15
2025-08-11 20:28:06,522 - ERROR - Failed to generate chunks | Error: No documents were found | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 39
2025-08-11 20:28:06,522 - ERROR - Failed to craete new vectorstore  | Error: No chunks were found.. | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 34
2025-08-11 20:28:06,522 - INFO - Vectorstore created sucesfully....
2025-08-11 20:28:35,044 - INFO - MAking the vectorstore....
2025-08-11 20:28:35,044 - ERROR - Failed to load PDF | Error: Data path doesn't exist | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 15
2025-08-11 20:28:35,044 - ERROR - Failed to generate chunks | Error: No documents were found | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 39
2025-08-11 20:28:35,044 - ERROR - Failed to craete new vectorstore  | Error: No chunks were found.. | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 34
2025-08-11 20:28:35,044 - INFO - Vectorstore created sucesfully....
2025-08-11 20:35:45,136 - INFO - MAking the vectorstore....
2025-08-11 20:35:45,137 - ERROR - Failed to load PDF | Error: Data path doesn't exist | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 15
2025-08-11 20:35:45,137 - ERROR - Failed to generate chunks | Error: No documents were found | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 39
2025-08-11 20:35:45,137 - ERROR - Failed to craete new vectorstore  | Error: No chunks were found.. | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 35
2025-08-11 20:35:45,137 - INFO - Vectorstore created sucesfully....
2025-08-11 20:40:07,151 - INFO - MAking the vectorstore....
2025-08-11 20:40:07,151 - ERROR - Failed to load PDF | Error: Data path doesn't exist | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 71
2025-08-11 20:40:07,151 - ERROR - Failed to generate chunks | Error: No documents were found | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 112
2025-08-11 20:40:07,152 - ERROR - Failed to craete new vectorstore  | Error: No chunks were found.. | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 35
2025-08-11 20:40:07,152 - INFO - Vectorstore created sucesfully....
2025-08-11 20:42:29,698 - INFO - MAking the vectorstore....
2025-08-11 20:42:29,698 - ERROR - Failed to load PDF | Error: Data path doesn't exist | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 72
2025-08-11 20:42:29,698 - ERROR - Failed to generate chunks | Error: No documents were found | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 113
2025-08-11 20:42:29,698 - ERROR - Failed to craete new vectorstore  | Error: No chunks were found.. | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 35
2025-08-11 20:42:29,698 - INFO - Vectorstore created sucesfully....
2025-08-11 20:50:36,649 - INFO - MAking the vectorstore....
2025-08-11 20:50:36,649 - ERROR - Failed to load PDF | Error: Data path doesn't exist | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 77
2025-08-11 20:50:36,649 - ERROR - Failed to generate chunks | Error: No documents were found | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/pdf_loader.py | Line: 118
2025-08-11 20:50:36,649 - ERROR - Failed to craete new vectorstore  | Error: No chunks were found.. | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 35
2025-08-11 20:50:36,649 - INFO - Vectorstore created sucesfully....
2025-08-11 20:53:13,455 - INFO - MAking the vectorstore....
2025-08-11 20:53:13,455 - INFO - loading files from data/
2025-08-11 20:53:20,437 - INFO - Succesfully fetched 759 documents
2025-08-11 20:53:20,437 - INFO - Splitting 759 documents into chunks
2025-08-11 20:53:20,538 - INFO - Generated 7094 text chunks
2025-08-11 20:53:20,538 - INFO - Generating your new vectorstore
2025-08-11 20:53:20,538 - INFO - Initializing our Huggingface embedding model
2025-08-11 20:54:43,928 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 20:54:43,929 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 20:54:46,684 - INFO - Use pytorch device_name: mps
2025-08-11 20:54:46,684 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 20:54:48,756 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 20:55:12,784 - INFO - Loading faiss.
2025-08-11 20:55:13,635 - INFO - Successfully loaded faiss.
2025-08-11 20:55:13,793 - INFO - Saving vectorstore
2025-08-11 20:55:13,817 - INFO - Vectostore saved sucesfulyy...
2025-08-11 20:55:13,819 - INFO - Vectorstore created sucesfully....
2025-08-11 20:58:06,269 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 20:58:06,269 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 20:58:19,967 - INFO - 127.0.0.1 - - [11/Aug/2025 20:58:19] "GET / HTTP/1.1" 200 -
2025-08-11 20:58:33,824 - INFO - Loading vector store for context
2025-08-11 20:58:33,825 - INFO - Initializing our Huggingface embedding model
2025-08-11 20:58:34,020 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 20:58:40,612 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 20:58:40,613 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 20:58:42,244 - INFO - Use pytorch device_name: mps
2025-08-11 20:58:42,245 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 20:58:43,976 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 20:58:43,976 - INFO - Loading existing vectorstore...
2025-08-11 20:58:43,978 - INFO - Loading faiss.
2025-08-11 20:58:44,019 - INFO - Successfully loaded faiss.
2025-08-11 20:58:44,051 - INFO - Loading LLM from HuggingFace
2025-08-11 20:58:44,100 - INFO - LLM loaded sucesfully...
2025-08-11 20:58:44,101 - INFO - Sucesfully created the QA chain
2025-08-11 20:58:45,258 - INFO - 127.0.0.1 - - [11/Aug/2025 20:58:45] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 20:58:45,268 - INFO - 127.0.0.1 - - [11/Aug/2025 20:58:45] "GET / HTTP/1.1" 200 -
2025-08-11 21:00:58,942 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 21:00:58,942 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 21:01:02,523 - INFO - 127.0.0.1 - - [11/Aug/2025 21:01:02] "GET / HTTP/1.1" 200 -
2025-08-11 21:01:12,313 - INFO - Loading vector store for context
2025-08-11 21:01:12,313 - INFO - Initializing our Huggingface embedding model
2025-08-11 21:01:12,708 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 21:01:18,427 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 21:01:18,428 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 21:01:20,326 - INFO - Use pytorch device_name: mps
2025-08-11 21:01:20,326 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 21:01:22,326 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 21:01:22,327 - INFO - Loading existing vectorstore...
2025-08-11 21:01:22,330 - INFO - Loading faiss.
2025-08-11 21:01:22,377 - INFO - Successfully loaded faiss.
2025-08-11 21:01:22,450 - INFO - Loading LLM from HuggingFace
2025-08-11 21:01:22,516 - INFO - LLM loaded sucesfully...
2025-08-11 21:01:22,517 - INFO - Sucesfully created the QA chain
2025-08-11 21:01:22,861 - INFO - 127.0.0.1 - - [11/Aug/2025 21:01:22] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 21:01:22,873 - INFO - 127.0.0.1 - - [11/Aug/2025 21:01:22] "GET / HTTP/1.1" 200 -
2025-08-11 21:29:17,816 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 21:29:17,816 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 21:29:21,210 - INFO - 127.0.0.1 - - [11/Aug/2025 21:29:21] "GET / HTTP/1.1" 200 -
2025-08-11 21:29:22,939 - INFO - 127.0.0.1 - - [11/Aug/2025 21:29:22] "GET / HTTP/1.1" 200 -
2025-08-11 21:29:30,607 - INFO - Loading vector store for context
2025-08-11 21:29:30,607 - INFO - Initializing our Huggingface embedding model
2025-08-11 21:29:30,818 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 21:29:36,554 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 21:29:36,554 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 21:29:38,758 - INFO - Use pytorch device_name: mps
2025-08-11 21:29:38,758 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 21:29:40,508 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 21:29:40,508 - INFO - Loading existing vectorstore...
2025-08-11 21:29:40,511 - INFO - Loading faiss.
2025-08-11 21:29:40,554 - INFO - Successfully loaded faiss.
2025-08-11 21:29:40,648 - INFO - Sucesfully created the QA chain
2025-08-11 21:29:41,021 - INFO - 127.0.0.1 - - [11/Aug/2025 21:29:41] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 21:29:41,026 - INFO - 127.0.0.1 - - [11/Aug/2025 21:29:41] "GET / HTTP/1.1" 200 -
2025-08-11 21:35:00,503 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 21:35:00,503 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 21:35:04,470 - INFO - 127.0.0.1 - - [11/Aug/2025 21:35:04] "GET / HTTP/1.1" 200 -
2025-08-11 21:35:16,524 - INFO - Loading vector store for context
2025-08-11 21:35:16,525 - INFO - Initializing our Huggingface embedding model
2025-08-11 21:35:16,762 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 21:35:22,659 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 21:35:22,659 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 21:35:24,426 - INFO - Use pytorch device_name: mps
2025-08-11 21:35:24,426 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 21:35:26,409 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 21:35:26,409 - INFO - Loading existing vectorstore...
2025-08-11 21:35:26,412 - INFO - Loading faiss.
2025-08-11 21:35:26,469 - INFO - Successfully loaded faiss.
2025-08-11 21:35:26,550 - INFO - Sucesfully created the QA chain
2025-08-11 21:35:26,935 - INFO - 127.0.0.1 - - [11/Aug/2025 21:35:26] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 21:35:26,947 - INFO - 127.0.0.1 - - [11/Aug/2025 21:35:26] "GET / HTTP/1.1" 200 -
2025-08-11 22:42:48,948 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 22:42:48,948 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 22:42:51,671 - INFO - 127.0.0.1 - - [11/Aug/2025 22:42:51] "GET / HTTP/1.1" 200 -
2025-08-11 22:42:57,860 - INFO - Loading vector store for context
2025-08-11 22:42:57,860 - INFO - Initializing our Huggingface embedding model
2025-08-11 22:42:58,060 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 22:43:04,612 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 22:43:04,613 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 22:43:06,397 - INFO - Use pytorch device_name: mps
2025-08-11 22:43:06,397 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 22:43:08,161 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 22:43:08,162 - INFO - Loading existing vectorstore...
2025-08-11 22:43:08,166 - INFO - Loading faiss.
2025-08-11 22:43:08,212 - INFO - Successfully loaded faiss.
2025-08-11 22:43:08,288 - INFO - Sucesfully created the QA chain
2025-08-11 22:43:08,655 - INFO - 127.0.0.1 - - [11/Aug/2025 22:43:08] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 22:43:08,664 - INFO - 127.0.0.1 - - [11/Aug/2025 22:43:08] "GET / HTTP/1.1" 200 -
2025-08-11 22:49:44,055 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 22:49:44,056 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 22:49:46,597 - INFO - 127.0.0.1 - - [11/Aug/2025 22:49:46] "GET / HTTP/1.1" 200 -
2025-08-11 22:49:55,484 - INFO - Loading vector store for context
2025-08-11 22:49:55,485 - INFO - Initializing our Huggingface embedding model
2025-08-11 22:49:55,696 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 22:50:02,231 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 22:50:02,232 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 22:50:04,419 - INFO - Use pytorch device_name: mps
2025-08-11 22:50:04,419 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 22:50:06,259 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 22:50:06,259 - INFO - Loading existing vectorstore...
2025-08-11 22:50:06,262 - INFO - Loading faiss.
2025-08-11 22:50:06,307 - INFO - Successfully loaded faiss.
2025-08-11 22:50:06,390 - INFO - Sucesfully created the QA chain
2025-08-11 22:50:06,821 - INFO - 127.0.0.1 - - [11/Aug/2025 22:50:06] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 22:50:06,827 - INFO - 127.0.0.1 - - [11/Aug/2025 22:50:06] "GET / HTTP/1.1" 200 -
2025-08-11 22:50:58,039 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 22:50:58,039 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 22:51:06,686 - INFO - Loading vector store for context
2025-08-11 22:51:06,686 - INFO - Initializing our Huggingface embedding model
2025-08-11 22:51:06,874 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 22:51:12,393 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 22:51:12,393 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 22:51:13,873 - INFO - Use pytorch device_name: mps
2025-08-11 22:51:13,873 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 22:51:15,526 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 22:51:15,527 - INFO - Loading existing vectorstore...
2025-08-11 22:51:15,530 - INFO - Loading faiss.
2025-08-11 22:51:15,579 - INFO - Successfully loaded faiss.
2025-08-11 22:51:15,618 - ERROR - Failed to make a QA chain | Error: 1 validation error for HuggingFaceEndpoint
  Value error, Please specify either a `model` OR an `endpoint_url` OR a `repo_id`,not more than one. [type=value_error, input_value={'repo_id': 'meta-llama/L...ns', 'model_kwargs': {}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/value_error | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 94
2025-08-11 22:51:15,622 - INFO - 127.0.0.1 - - [11/Aug/2025 22:51:15] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 22:51:15,633 - INFO - 127.0.0.1 - - [11/Aug/2025 22:51:15] "GET / HTTP/1.1" 200 -
2025-08-11 22:52:08,904 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 22:52:08,904 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 22:52:19,348 - INFO - Loading vector store for context
2025-08-11 22:52:19,349 - INFO - Initializing our Huggingface embedding model
2025-08-11 22:52:19,536 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 22:52:24,837 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 22:52:24,837 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 22:52:26,503 - INFO - Use pytorch device_name: mps
2025-08-11 22:52:26,504 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 22:52:28,130 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 22:52:28,130 - INFO - Loading existing vectorstore...
2025-08-11 22:52:28,133 - INFO - Loading faiss.
2025-08-11 22:52:28,176 - INFO - Successfully loaded faiss.
2025-08-11 22:52:28,212 - ERROR - Failed to make a QA chain | Error: 1 validation error for HuggingFaceEndpoint
  Value error, Please specify either a `model` OR an `endpoint_url` OR a `repo_id`,not more than one. [type=value_error, input_value={'repo_id': 'meta-llama/L...ns', 'model_kwargs': {}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/value_error | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 94
2025-08-11 22:52:28,218 - INFO - 127.0.0.1 - - [11/Aug/2025 22:52:28] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 22:52:28,227 - INFO - 127.0.0.1 - - [11/Aug/2025 22:52:28] "GET / HTTP/1.1" 200 -
2025-08-11 23:09:37,344 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 23:09:37,349 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 23:09:42,669 - INFO - 127.0.0.1 - - [11/Aug/2025 23:09:42] "GET / HTTP/1.1" 200 -
2025-08-11 23:09:48,557 - INFO - Loading vector store for context
2025-08-11 23:09:48,558 - INFO - Initializing our Huggingface embedding model
2025-08-11 23:09:48,787 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 23:09:54,932 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 23:09:54,932 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 23:09:57,111 - INFO - Use pytorch device_name: mps
2025-08-11 23:09:57,111 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 23:09:58,998 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 23:09:58,998 - INFO - Loading existing vectorstore...
2025-08-11 23:09:59,003 - INFO - Loading faiss.
2025-08-11 23:09:59,055 - INFO - Successfully loaded faiss.
2025-08-11 23:09:59,143 - INFO - Sucesfully created the QA chain
2025-08-11 23:09:59,503 - INFO - 127.0.0.1 - - [11/Aug/2025 23:09:59] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 23:09:59,530 - INFO - 127.0.0.1 - - [11/Aug/2025 23:09:59] "GET / HTTP/1.1" 200 -
2025-08-11 23:12:03,789 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 23:12:03,789 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 23:12:12,085 - INFO - 127.0.0.1 - - [11/Aug/2025 23:12:12] "GET / HTTP/1.1" 200 -
2025-08-11 23:12:14,802 - INFO - Loading vector store for context
2025-08-11 23:12:14,802 - INFO - Initializing our Huggingface embedding model
2025-08-11 23:12:15,013 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 23:12:21,377 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 23:12:21,377 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 23:12:23,048 - INFO - Use pytorch device_name: mps
2025-08-11 23:12:23,049 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 23:12:24,819 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 23:12:24,820 - INFO - Loading existing vectorstore...
2025-08-11 23:12:24,824 - INFO - Loading faiss.
2025-08-11 23:12:24,876 - INFO - Successfully loaded faiss.
2025-08-11 23:12:24,967 - INFO - Sucesfully created the QA chain
2025-08-11 23:12:25,376 - INFO - 127.0.0.1 - - [11/Aug/2025 23:12:25] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 23:12:25,390 - INFO - 127.0.0.1 - - [11/Aug/2025 23:12:25] "GET / HTTP/1.1" 200 -
2025-08-11 23:13:52,126 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 23:13:52,126 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 23:14:02,134 - INFO - Loading vector store for context
2025-08-11 23:14:02,134 - INFO - Initializing our Huggingface embedding model
2025-08-11 23:14:02,327 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 23:14:08,938 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 23:14:08,938 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 23:14:10,784 - INFO - Use pytorch device_name: mps
2025-08-11 23:14:10,784 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 23:14:12,528 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 23:14:12,528 - INFO - Loading existing vectorstore...
2025-08-11 23:14:12,530 - INFO - Loading faiss.
2025-08-11 23:14:12,577 - INFO - Successfully loaded faiss.
2025-08-11 23:14:12,668 - INFO - Sucesfully created the QA chain
2025-08-11 23:14:13,551 - INFO - 127.0.0.1 - - [11/Aug/2025 23:14:13] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 23:14:13,565 - INFO - 127.0.0.1 - - [11/Aug/2025 23:14:13] "GET / HTTP/1.1" 200 -
2025-08-11 23:14:31,173 - INFO - Loading vector store for context
2025-08-11 23:14:31,173 - INFO - Initializing our Huggingface embedding model
2025-08-11 23:14:31,301 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 23:14:31,302 - INFO - Use pytorch device_name: mps
2025-08-11 23:14:31,302 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 23:14:33,119 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 23:14:33,119 - INFO - Loading existing vectorstore...
2025-08-11 23:14:33,142 - INFO - Sucesfully created the QA chain
2025-08-11 23:14:33,716 - INFO - 127.0.0.1 - - [11/Aug/2025 23:14:33] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 23:14:33,722 - INFO - 127.0.0.1 - - [11/Aug/2025 23:14:33] "GET / HTTP/1.1" 200 -
2025-08-11 23:14:44,235 - INFO - Loading vector store for context
2025-08-11 23:14:44,236 - INFO - Initializing our Huggingface embedding model
2025-08-11 23:14:44,381 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 23:14:44,383 - INFO - Use pytorch device_name: mps
2025-08-11 23:14:44,383 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 23:14:45,861 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 23:14:45,862 - INFO - Loading existing vectorstore...
2025-08-11 23:14:45,889 - INFO - Sucesfully created the QA chain
2025-08-11 23:14:46,270 - INFO - 127.0.0.1 - - [11/Aug/2025 23:14:46] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 23:14:46,277 - INFO - 127.0.0.1 - - [11/Aug/2025 23:14:46] "GET / HTTP/1.1" 200 -
2025-08-11 23:19:11,642 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 23:19:11,642 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 23:19:15,219 - INFO - 127.0.0.1 - - [11/Aug/2025 23:19:15] "GET / HTTP/1.1" 200 -
2025-08-11 23:19:32,832 - INFO - Loading vector store for context
2025-08-11 23:19:32,833 - INFO - Initializing our Huggingface embedding model
2025-08-11 23:19:33,056 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 23:19:39,665 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 23:19:39,665 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 23:19:41,518 - INFO - Use pytorch device_name: mps
2025-08-11 23:19:41,518 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 23:19:43,466 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 23:19:43,466 - INFO - Loading existing vectorstore...
2025-08-11 23:19:43,469 - INFO - Loading faiss.
2025-08-11 23:19:43,518 - INFO - Successfully loaded faiss.
2025-08-11 23:19:43,617 - INFO - Sucesfully created the QA chain
2025-08-11 23:19:44,409 - INFO - 127.0.0.1 - - [11/Aug/2025 23:19:44] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 23:19:44,415 - INFO - 127.0.0.1 - - [11/Aug/2025 23:19:44] "GET / HTTP/1.1" 200 -
2025-08-11 23:22:13,915 - INFO - 127.0.0.1 - - [11/Aug/2025 23:22:13] "GET / HTTP/1.1" 200 -
2025-08-11 23:22:15,174 - INFO - 127.0.0.1 - - [11/Aug/2025 23:22:15] "GET / HTTP/1.1" 200 -
2025-08-11 23:22:23,840 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 23:22:23,842 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 23:22:32,309 - INFO - 127.0.0.1 - - [11/Aug/2025 23:22:32] "GET / HTTP/1.1" 200 -
2025-08-11 23:23:02,483 - INFO - Loading vector store for context
2025-08-11 23:23:02,483 - INFO - Initializing our Huggingface embedding model
2025-08-11 23:23:02,689 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-11 23:23:09,677 - INFO - Note: NumExpr detected 10 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2025-08-11 23:23:09,677 - INFO - NumExpr defaulting to 8 threads.
2025-08-11 23:23:11,931 - INFO - Use pytorch device_name: mps
2025-08-11 23:23:11,931 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-11 23:23:13,756 - INFO - Huggingface embedding model loaded successfully....
2025-08-11 23:23:13,756 - INFO - Loading existing vectorstore...
2025-08-11 23:23:13,758 - INFO - Loading faiss.
2025-08-11 23:23:13,842 - INFO - Successfully loaded faiss.
2025-08-11 23:23:13,965 - INFO - Sucesfully created the QA chain
2025-08-11 23:23:15,440 - INFO - 127.0.0.1 - - [11/Aug/2025 23:23:15] "[32mPOST / HTTP/1.1[0m" 302 -
2025-08-11 23:23:15,454 - INFO - 127.0.0.1 - - [11/Aug/2025 23:23:15] "GET / HTTP/1.1" 200 -
2025-08-11 23:23:44,699 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 23:23:44,699 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 23:23:47,122 - INFO - 127.0.0.1 - - [11/Aug/2025 23:23:47] "GET / HTTP/1.1" 200 -
2025-08-11 23:23:49,108 - INFO - 127.0.0.1 - - [11/Aug/2025 23:23:49] "GET / HTTP/1.1" 200 -
2025-08-11 23:23:49,916 - INFO - 127.0.0.1 - - [11/Aug/2025 23:23:49] "GET / HTTP/1.1" 200 -
2025-08-11 23:23:50,347 - INFO - 127.0.0.1 - - [11/Aug/2025 23:23:50] "GET / HTTP/1.1" 200 -
2025-08-11 23:23:59,944 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-11 23:23:59,945 - INFO - [33mPress CTRL+C to quit[0m
2025-08-11 23:24:01,676 - INFO - 127.0.0.1 - - [11/Aug/2025 23:24:01] "GET / HTTP/1.1" 200 -
