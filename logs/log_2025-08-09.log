2025-08-09 00:44:38,012 - INFO - MAking the vectorstore....
2025-08-09 00:44:38,013 - INFO - loading files from data/
2025-08-09 00:44:45,902 - INFO - Succesfully fetched 759 documents
2025-08-09 00:44:45,902 - INFO - Splitting 759 documents into chunks
2025-08-09 00:44:46,004 - INFO - Generated 7080 text chunks
2025-08-09 00:44:46,004 - INFO - Generating your new vectorstore
2025-08-09 00:44:46,004 - INFO - Intializing our Huggingface embedding model
2025-08-09 00:44:46,004 - ERROR - Error occured while loading embedding model | Error: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 00:44:46,004 - ERROR - Failed to craete new vectorstore  | Error: Error occured while loading embedding model | Error: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 38
2025-08-09 00:44:46,004 - INFO - Vectorstore created sucesfully....
2025-08-09 00:47:10,675 - INFO - MAking the vectorstore....
2025-08-09 00:47:10,675 - INFO - loading files from data/
2025-08-09 00:47:19,890 - INFO - Succesfully fetched 759 documents
2025-08-09 00:47:19,890 - INFO - Splitting 759 documents into chunks
2025-08-09 00:47:19,991 - INFO - Generated 7080 text chunks
2025-08-09 00:47:19,992 - INFO - Generating your new vectorstore
2025-08-09 00:47:19,992 - INFO - Intializing our Huggingface embedding model
2025-08-09 00:47:50,436 - INFO - Use pytorch device_name: mps
2025-08-09 00:47:50,436 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 00:47:56,805 - INFO - Huggingface embedding model loaded sucesfully....
2025-08-09 00:48:15,153 - INFO - Loading faiss.
2025-08-09 00:48:15,779 - INFO - Successfully loaded faiss.
2025-08-09 00:48:15,794 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 00:48:15,927 - INFO - Saving vectorstore
2025-08-09 00:48:15,955 - INFO - Vectostore saved sucesfulyy...
2025-08-09 00:48:15,957 - INFO - Vectorstore created sucesfully....
2025-08-09 01:39:48,843 - INFO - MAking the vectorstore....
2025-08-09 01:39:48,843 - INFO - loading files from data/
2025-08-09 01:39:56,490 - INFO - Succesfully fetched 759 documents
2025-08-09 01:39:56,490 - INFO - Splitting 759 documents into chunks
2025-08-09 01:39:56,593 - INFO - Generated 7080 text chunks
2025-08-09 01:39:56,593 - INFO - Generating your new vectorstore
2025-08-09 01:39:56,593 - INFO - Intializing our Huggingface embedding model
2025-08-09 01:40:01,480 - INFO - Use pytorch device_name: mps
2025-08-09 01:40:01,480 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 01:40:03,744 - INFO - Huggingface embedding model loaded sucesfully....
2025-08-09 01:40:18,062 - INFO - Loading faiss.
2025-08-09 01:40:18,127 - INFO - Successfully loaded faiss.
2025-08-09 01:40:18,131 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 01:40:18,258 - INFO - Saving vectorstore
2025-08-09 01:40:18,290 - INFO - Vectostore saved sucesfulyy...
2025-08-09 01:40:18,292 - INFO - Vectorstore created sucesfully....
2025-08-09 02:36:37,816 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.103:8000
2025-08-09 02:36:37,816 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 02:38:26,304 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.103:8000
2025-08-09 02:38:26,304 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 02:38:45,054 - INFO - 127.0.0.1 - - [09/Aug/2025 02:38:45] "GET / HTTP/1.1" 200 -
2025-08-09 02:38:45,284 - INFO - 127.0.0.1 - - [09/Aug/2025 02:38:45] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-09 02:38:55,810 - INFO - Loading vector store for context
2025-08-09 02:38:55,811 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:39:00,594 - INFO - Use pytorch device_name: mps
2025-08-09 02:39:00,594 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:39:01,471 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:39:01,472 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:39:01,472 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:39:01,472 - INFO - 127.0.0.1 - - [09/Aug/2025 02:39:01] "POST / HTTP/1.1" 200 -
2025-08-09 02:39:13,595 - INFO - Loading vector store for context
2025-08-09 02:39:13,596 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:39:13,596 - INFO - Use pytorch device_name: mps
2025-08-09 02:39:13,596 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:39:14,674 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:39:14,674 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:39:14,674 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:39:14,675 - INFO - 127.0.0.1 - - [09/Aug/2025 02:39:14] "POST / HTTP/1.1" 200 -
2025-08-09 02:40:48,931 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.103:8000
2025-08-09 02:40:48,931 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 02:40:54,778 - INFO - Loading vector store for context
2025-08-09 02:40:54,778 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:40:59,384 - INFO - Use pytorch device_name: mps
2025-08-09 02:40:59,384 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:41:00,225 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:41:00,225 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:41:00,225 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:41:00,231 - INFO - 127.0.0.1 - - [09/Aug/2025 02:41:00] "POST / HTTP/1.1" 200 -
2025-08-09 02:41:10,414 - INFO - Loading vector store for context
2025-08-09 02:41:10,414 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:41:10,415 - INFO - Use pytorch device_name: mps
2025-08-09 02:41:10,415 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:41:11,292 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:41:11,292 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:41:11,292 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:41:11,292 - INFO - 127.0.0.1 - - [09/Aug/2025 02:41:11] "POST / HTTP/1.1" 200 -
2025-08-09 02:46:25,406 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.103:8000
2025-08-09 02:46:25,407 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 02:46:30,622 - INFO - Loading vector store for context
2025-08-09 02:46:30,622 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:46:35,007 - INFO - Use pytorch device_name: mps
2025-08-09 02:46:35,008 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:46:35,169 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.
2025-08-09 02:46:35,286 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:46:35,287 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:46:35,287 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:46:35,291 - INFO - 127.0.0.1 - - [09/Aug/2025 02:46:35] "POST / HTTP/1.1" 200 -
2025-08-09 02:49:34,795 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 02:49:34,796 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 02:49:50,106 - INFO - 127.0.0.1 - - [09/Aug/2025 02:49:50] "GET / HTTP/1.1" 200 -
2025-08-09 02:49:50,334 - INFO - 127.0.0.1 - - [09/Aug/2025 02:49:50] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-09 02:49:57,479 - INFO - Loading vector store for context
2025-08-09 02:49:57,479 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:50:02,070 - INFO - Use pytorch device_name: mps
2025-08-09 02:50:02,070 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:50:02,218 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.
2025-08-09 02:50:02,339 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:50:02,339 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:50:02,339 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:50:02,340 - INFO - 127.0.0.1 - - [09/Aug/2025 02:50:02] "POST / HTTP/1.1" 200 -
2025-08-09 02:53:45,872 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 02:53:45,872 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 02:53:51,230 - INFO - Loading vector store for context
2025-08-09 02:53:51,230 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:53:55,472 - INFO - Use pytorch device_name: mps
2025-08-09 02:53:55,472 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:53:55,621 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.
2025-08-09 02:53:55,730 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:53:55,730 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:53:55,730 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:53:55,735 - INFO - 127.0.0.1 - - [09/Aug/2025 02:53:55] "POST / HTTP/1.1" 200 -
2025-08-09 02:54:03,627 - INFO - Loading vector store for context
2025-08-09 02:54:03,627 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:54:03,627 - INFO - Use pytorch device_name: mps
2025-08-09 02:54:03,627 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:54:03,742 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.
2025-08-09 02:54:03,854 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:54:03,854 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:54:03,854 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:54:03,855 - INFO - 127.0.0.1 - - [09/Aug/2025 02:54:03] "POST / HTTP/1.1" 200 -
2025-08-09 02:54:13,514 - INFO - Loading vector store for context
2025-08-09 02:54:13,514 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:54:13,514 - INFO - Use pytorch device_name: mps
2025-08-09 02:54:13,515 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 02:54:13,627 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.
2025-08-09 02:54:13,735 - ERROR - Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12
2025-08-09 02:54:13,735 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: sentence-transformers/all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>` | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 12 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:54:13,735 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:54:13,735 - INFO - 127.0.0.1 - - [09/Aug/2025 02:54:13] "POST / HTTP/1.1" 200 -
2025-08-09 02:58:42,765 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 02:58:42,765 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 02:58:51,881 - INFO - Loading vector store for context
2025-08-09 02:58:51,881 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:58:51,881 - ERROR - Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 14
2025-08-09 02:58:51,881 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 14 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:58:51,881 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:58:51,885 - INFO - 127.0.0.1 - - [09/Aug/2025 02:58:51] "POST / HTTP/1.1" 200 -
2025-08-09 02:59:00,290 - INFO - Loading vector store for context
2025-08-09 02:59:00,290 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:59:00,290 - ERROR - Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 14
2025-08-09 02:59:00,290 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 14 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:59:00,290 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:59:00,291 - INFO - 127.0.0.1 - - [09/Aug/2025 02:59:00] "POST / HTTP/1.1" 200 -
2025-08-09 02:59:02,671 - INFO - 127.0.0.1 - - [09/Aug/2025 02:59:02] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 02:59:02,674 - INFO - 127.0.0.1 - - [09/Aug/2025 02:59:02] "GET / HTTP/1.1" 200 -
2025-08-09 02:59:08,547 - INFO - Loading vector store for context
2025-08-09 02:59:08,547 - INFO - Intializing our Huggingface embedding model
2025-08-09 02:59:08,547 - ERROR - Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 14
2025-08-09 02:59:08,547 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 14 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 02:59:08,547 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 02:59:08,548 - INFO - 127.0.0.1 - - [09/Aug/2025 02:59:08] "POST / HTTP/1.1" 200 -
2025-08-09 03:02:25,331 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:02:25,331 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:02:30,369 - INFO - Loading vector store for context
2025-08-09 03:02:30,369 - INFO - Intializing our Huggingface embedding model
2025-08-09 03:02:30,370 - ERROR - Error occured while loading embedding model | Error: 1 validation error for HuggingFaceEmbeddings
huggingfacehub_api_token
  Extra inputs are not permitted [type=extra_forbidden, input_value='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', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 13
2025-08-09 03:02:30,370 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: 1 validation error for HuggingFaceEmbeddings
huggingfacehub_api_token
  Extra inputs are not permitted [type=extra_forbidden, input_value='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', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 13 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:02:30,370 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:02:30,375 - INFO - 127.0.0.1 - - [09/Aug/2025 03:02:30] "POST / HTTP/1.1" 200 -
2025-08-09 03:02:33,613 - INFO - 127.0.0.1 - - [09/Aug/2025 03:02:33] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:02:33,616 - INFO - 127.0.0.1 - - [09/Aug/2025 03:02:33] "GET / HTTP/1.1" 200 -
2025-08-09 03:03:56,193 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:03:56,193 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:04:13,981 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:04:13,981 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:04:29,029 - INFO - 127.0.0.1 - - [09/Aug/2025 03:04:29] "GET / HTTP/1.1" 200 -
2025-08-09 03:04:39,022 - INFO - Loading vector store for context
2025-08-09 03:04:39,022 - INFO - Intializing our Huggingface embedding model
2025-08-09 03:04:39,023 - ERROR - Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 40
2025-08-09 03:04:39,023 - ERROR - Failed to load vectorstore | Error: Error occured while loading embedding model | Error: name 'os' is not defined | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 40 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:04:39,023 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:04:39,023 - INFO - 127.0.0.1 - - [09/Aug/2025 03:04:39] "POST / HTTP/1.1" 200 -
2025-08-09 03:07:20,109 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:07:20,109 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:07:23,383 - INFO - Loading vector store for context
2025-08-09 03:07:23,383 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:07:23,573 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:07:23,573 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:07:23,573 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:07:23,578 - INFO - 127.0.0.1 - - [09/Aug/2025 03:07:23] "POST / HTTP/1.1" 200 -
2025-08-09 03:07:25,809 - INFO - 127.0.0.1 - - [09/Aug/2025 03:07:25] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:07:25,812 - INFO - 127.0.0.1 - - [09/Aug/2025 03:07:25] "GET / HTTP/1.1" 200 -
2025-08-09 03:08:14,117 - INFO - Loading vector store for context
2025-08-09 03:08:14,117 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:08:14,237 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:08:14,237 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:08:14,237 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:08:14,237 - INFO - 127.0.0.1 - - [09/Aug/2025 03:08:14] "POST / HTTP/1.1" 200 -
2025-08-09 03:16:10,528 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:16:10,528 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:16:19,908 - INFO - Loading vector store for context
2025-08-09 03:16:19,909 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:16:20,096 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:16:21,434 - INFO - 127.0.0.1 - - [09/Aug/2025 03:16:21] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:16:21,442 - INFO - 127.0.0.1 - - [09/Aug/2025 03:16:21] "GET / HTTP/1.1" 200 -
2025-08-09 03:16:24,561 - INFO - Use pytorch device_name: mps
2025-08-09 03:16:24,562 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:16:31,488 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:16:31,488 - INFO - Loading existing vectorstore...
2025-08-09 03:16:31,491 - INFO - Loading faiss.
2025-08-09 03:16:31,557 - INFO - Successfully loaded faiss.
2025-08-09 03:16:31,561 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 03:16:31,590 - INFO - Loading LLM from HuggingFace
2025-08-09 03:16:31,715 - INFO - LLM loaded sucesfully...
2025-08-09 03:16:31,716 - INFO - Sucesfully created the QA chain
2025-08-09 03:16:34,302 - INFO - 127.0.0.1 - - [09/Aug/2025 03:16:34] "POST / HTTP/1.1" 200 -
2025-08-09 03:16:44,091 - INFO - Loading vector store for context
2025-08-09 03:16:44,092 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:16:44,225 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:16:44,225 - INFO - Use pytorch device_name: mps
2025-08-09 03:16:44,225 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:16:46,095 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:16:46,095 - INFO - Loading existing vectorstore...
2025-08-09 03:16:46,260 - INFO - Loading LLM from HuggingFace
2025-08-09 03:16:46,261 - INFO - LLM loaded sucesfully...
2025-08-09 03:16:46,261 - INFO - Sucesfully created the QA chain
2025-08-09 03:16:46,285 - INFO - 127.0.0.1 - - [09/Aug/2025 03:16:46] "POST / HTTP/1.1" 200 -
2025-08-09 03:17:11,165 - INFO - Loading vector store for context
2025-08-09 03:17:11,166 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:17:11,293 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:17:11,293 - INFO - Use pytorch device_name: mps
2025-08-09 03:17:11,293 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:17:13,053 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:17:13,054 - INFO - Loading existing vectorstore...
2025-08-09 03:17:13,075 - INFO - Loading LLM from HuggingFace
2025-08-09 03:17:13,076 - INFO - LLM loaded sucesfully...
2025-08-09 03:17:13,077 - INFO - Sucesfully created the QA chain
2025-08-09 03:17:13,097 - INFO - 127.0.0.1 - - [09/Aug/2025 03:17:13] "POST / HTTP/1.1" 200 -
2025-08-09 03:23:15,358 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:23:15,359 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:23:20,829 - INFO - Loading vector store for context
2025-08-09 03:23:20,829 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:23:21,045 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:23:25,311 - INFO - Use pytorch device_name: mps
2025-08-09 03:23:25,311 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:23:27,427 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:23:27,429 - INFO - Loading existing vectorstore...
2025-08-09 03:23:27,432 - INFO - Loading faiss.
2025-08-09 03:23:27,465 - INFO - Successfully loaded faiss.
2025-08-09 03:23:27,469 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 03:23:27,497 - INFO - Loading LLM from HuggingFace
2025-08-09 03:23:27,553 - INFO - LLM loaded sucesfully...
2025-08-09 03:23:27,554 - INFO - Sucesfully created the QA chain
2025-08-09 03:23:28,211 - INFO - 127.0.0.1 - - [09/Aug/2025 03:23:28] "POST / HTTP/1.1" 200 -
2025-08-09 03:23:43,431 - INFO - Loading vector store for context
2025-08-09 03:23:43,431 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:23:43,553 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:23:43,554 - INFO - Use pytorch device_name: mps
2025-08-09 03:23:43,554 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:23:45,333 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:23:45,333 - INFO - Loading existing vectorstore...
2025-08-09 03:23:45,458 - INFO - Loading LLM from HuggingFace
2025-08-09 03:23:45,458 - INFO - LLM loaded sucesfully...
2025-08-09 03:23:45,458 - INFO - Sucesfully created the QA chain
2025-08-09 03:23:46,121 - INFO - 127.0.0.1 - - [09/Aug/2025 03:23:46] "POST / HTTP/1.1" 200 -
2025-08-09 03:24:04,513 - INFO - Loading vector store for context
2025-08-09 03:24:04,513 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:24:04,669 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:24:04,669 - INFO - Use pytorch device_name: mps
2025-08-09 03:24:04,669 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:24:06,454 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:24:06,454 - INFO - Loading existing vectorstore...
2025-08-09 03:24:06,477 - INFO - Loading LLM from HuggingFace
2025-08-09 03:24:06,477 - INFO - LLM loaded sucesfully...
2025-08-09 03:24:06,478 - INFO - Sucesfully created the QA chain
2025-08-09 03:24:07,098 - INFO - 127.0.0.1 - - [09/Aug/2025 03:24:07] "POST / HTTP/1.1" 200 -
2025-08-09 03:24:25,117 - INFO - 127.0.0.1 - - [09/Aug/2025 03:24:25] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:24:25,120 - INFO - 127.0.0.1 - - [09/Aug/2025 03:24:25] "GET / HTTP/1.1" 200 -
2025-08-09 03:24:30,690 - INFO - Loading vector store for context
2025-08-09 03:24:30,691 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:24:30,813 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:24:30,813 - INFO - Use pytorch device_name: mps
2025-08-09 03:24:30,813 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:24:32,726 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:24:32,726 - INFO - Loading existing vectorstore...
2025-08-09 03:24:32,752 - INFO - Loading LLM from HuggingFace
2025-08-09 03:24:32,753 - INFO - LLM loaded sucesfully...
2025-08-09 03:24:32,753 - INFO - Sucesfully created the QA chain
2025-08-09 03:24:32,788 - INFO - 127.0.0.1 - - [09/Aug/2025 03:24:32] "POST / HTTP/1.1" 200 -
2025-08-09 03:26:44,155 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:26:44,155 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:26:52,246 - INFO - Loading vector store for context
2025-08-09 03:26:52,247 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:26:52,423 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:26:56,642 - INFO - Use pytorch device_name: mps
2025-08-09 03:26:56,642 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:26:58,619 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:26:58,620 - INFO - Loading existing vectorstore...
2025-08-09 03:26:58,622 - INFO - Loading faiss.
2025-08-09 03:26:58,657 - INFO - Successfully loaded faiss.
2025-08-09 03:26:58,660 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 03:26:58,687 - INFO - Loading LLM from HuggingFace
2025-08-09 03:26:58,743 - INFO - LLM loaded sucesfully...
2025-08-09 03:26:58,743 - INFO - Sucesfully created the QA chain
2025-08-09 03:26:59,434 - INFO - 127.0.0.1 - - [09/Aug/2025 03:26:59] "POST / HTTP/1.1" 200 -
2025-08-09 03:27:05,143 - INFO - 127.0.0.1 - - [09/Aug/2025 03:27:05] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:27:05,146 - INFO - 127.0.0.1 - - [09/Aug/2025 03:27:05] "GET / HTTP/1.1" 200 -
2025-08-09 03:27:11,067 - INFO - Loading vector store for context
2025-08-09 03:27:11,067 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:27:11,207 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:27:11,208 - INFO - Use pytorch device_name: mps
2025-08-09 03:27:11,208 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:27:12,897 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:27:12,898 - INFO - Loading existing vectorstore...
2025-08-09 03:27:13,059 - INFO - Loading LLM from HuggingFace
2025-08-09 03:27:13,059 - INFO - LLM loaded sucesfully...
2025-08-09 03:27:13,060 - INFO - Sucesfully created the QA chain
2025-08-09 03:27:13,085 - INFO - 127.0.0.1 - - [09/Aug/2025 03:27:13] "POST / HTTP/1.1" 200 -
2025-08-09 03:28:38,196 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:28:38,196 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:28:47,344 - INFO - 127.0.0.1 - - [09/Aug/2025 03:28:47] "GET / HTTP/1.1" 200 -
2025-08-09 03:28:54,526 - INFO - Loading vector store for context
2025-08-09 03:28:54,526 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:28:54,723 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 03:28:58,662 - INFO - Use pytorch device_name: mps
2025-08-09 03:28:58,663 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 03:29:00,566 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 03:29:00,566 - INFO - Loading existing vectorstore...
2025-08-09 03:29:00,568 - INFO - Loading faiss.
2025-08-09 03:29:00,604 - INFO - Successfully loaded faiss.
2025-08-09 03:29:00,607 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 03:29:00,634 - INFO - Loading LLM from HuggingFace
2025-08-09 03:29:00,680 - INFO - LLM loaded sucesfully...
2025-08-09 03:29:00,680 - INFO - Sucesfully created the QA chain
2025-08-09 03:29:01,029 - INFO - 127.0.0.1 - - [09/Aug/2025 03:29:01] "POST / HTTP/1.1" 200 -
2025-08-09 03:35:29,193 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:35:29,193 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:35:33,215 - INFO - Loading vector store for context
2025-08-09 03:35:33,216 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:35:33,427 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:35:33,427 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:35:33,427 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:35:33,432 - INFO - 127.0.0.1 - - [09/Aug/2025 03:35:33] "POST / HTTP/1.1" 200 -
2025-08-09 03:35:37,119 - INFO - Loading vector store for context
2025-08-09 03:35:37,119 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:35:37,240 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:35:37,240 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:35:37,240 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:35:37,240 - INFO - 127.0.0.1 - - [09/Aug/2025 03:35:37] "POST / HTTP/1.1" 200 -
2025-08-09 03:36:13,149 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:36:13,149 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:36:17,326 - INFO - Loading vector store for context
2025-08-09 03:36:17,326 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:36:17,503 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:36:17,503 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:36:17,503 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:36:17,508 - INFO - 127.0.0.1 - - [09/Aug/2025 03:36:17] "POST / HTTP/1.1" 200 -
2025-08-09 03:36:18,146 - INFO - 127.0.0.1 - - [09/Aug/2025 03:36:18] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:36:18,150 - INFO - 127.0.0.1 - - [09/Aug/2025 03:36:18] "GET / HTTP/1.1" 200 -
2025-08-09 03:36:24,724 - INFO - Loading vector store for context
2025-08-09 03:36:24,724 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:36:24,842 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:36:24,842 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:36:24,842 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:36:24,843 - INFO - 127.0.0.1 - - [09/Aug/2025 03:36:24] "POST / HTTP/1.1" 200 -
2025-08-09 03:37:38,778 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:37:38,779 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:38:19,172 - INFO - Loading vector store for context
2025-08-09 03:38:19,172 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:38:19,359 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:38:19,359 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:38:19,360 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:38:19,366 - INFO - 127.0.0.1 - - [09/Aug/2025 03:38:19] "POST / HTTP/1.1" 200 -
2025-08-09 03:38:21,736 - INFO - 127.0.0.1 - - [09/Aug/2025 03:38:21] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:38:21,740 - INFO - 127.0.0.1 - - [09/Aug/2025 03:38:21] "GET / HTTP/1.1" 200 -
2025-08-09 03:38:31,293 - INFO - Loading vector store for context
2025-08-09 03:38:31,294 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:38:31,407 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:38:31,407 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:38:31,407 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:38:31,407 - INFO - 127.0.0.1 - - [09/Aug/2025 03:38:31] "POST / HTTP/1.1" 200 -
2025-08-09 03:39:42,657 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:39:42,657 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:39:46,898 - INFO - Loading vector store for context
2025-08-09 03:39:46,898 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:39:47,093 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:39:47,093 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:39:47,093 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:39:47,098 - INFO - 127.0.0.1 - - [09/Aug/2025 03:39:47] "POST / HTTP/1.1" 200 -
2025-08-09 03:41:03,321 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 03:41:03,322 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 03:42:27,303 - INFO - Loading vector store for context
2025-08-09 03:42:27,303 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:42:27,527 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:42:27,527 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:42:27,527 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:42:27,534 - INFO - 127.0.0.1 - - [09/Aug/2025 03:42:27] "POST / HTTP/1.1" 200 -
2025-08-09 03:42:30,572 - INFO - 127.0.0.1 - - [09/Aug/2025 03:42:30] "[32mGET /clear HTTP/1.1[0m" 302 -
2025-08-09 03:42:30,576 - INFO - 127.0.0.1 - - [09/Aug/2025 03:42:30] "GET / HTTP/1.1" 200 -
2025-08-09 03:42:38,198 - INFO - Loading vector store for context
2025-08-09 03:42:38,198 - INFO - Initializing our Huggingface embedding model
2025-08-09 03:42:38,311 - ERROR - Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41
2025-08-09 03:42:38,311 - ERROR - Failed to load vectorstore | Error: Error occurred while loading embedding model | Error: Invalid user token. The token from HF_TOKEN environment variable is invalid. Note that HF_TOKEN takes precedence over `hf auth login`. | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/embeddings.py | Line: 41 | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/vector_store.py | Line: 14
2025-08-09 03:42:38,311 - ERROR - Failed to make a QA chain | Error: Vector store not present or empty | Error: None | File: Unknown File | Line: Unknown Line | File: /Users/ridhampuri/Desktop/projectsmlpipelines/llmops_aiops/section9/medicalchatbot/RAG MEDICAL CHATBOT/app/components/retriever.py | Line: 34
2025-08-09 03:42:38,311 - INFO - 127.0.0.1 - - [09/Aug/2025 03:42:38] "POST / HTTP/1.1" 200 -
2025-08-09 05:45:23,308 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 05:45:23,308 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 05:45:58,510 - INFO - 127.0.0.1 - - [09/Aug/2025 05:45:58] "GET / HTTP/1.1" 200 -
2025-08-09 05:46:05,310 - INFO - Loading vector store for context
2025-08-09 05:46:05,310 - INFO - Initializing our Huggingface embedding model
2025-08-09 05:46:05,512 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 05:46:10,856 - INFO - Use pytorch device_name: mps
2025-08-09 05:46:10,856 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 05:46:13,576 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 05:46:13,577 - INFO - Loading existing vectorstore...
2025-08-09 05:46:13,579 - INFO - Loading faiss.
2025-08-09 05:46:13,624 - INFO - Successfully loaded faiss.
2025-08-09 05:46:13,628 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 05:46:13,652 - INFO - Loading LLM from HuggingFace
2025-08-09 05:46:13,702 - INFO - LLM loaded sucesfully...
2025-08-09 05:46:13,702 - INFO - Sucesfully created the QA chain
2025-08-09 05:46:14,092 - INFO - 127.0.0.1 - - [09/Aug/2025 05:46:14] "POST / HTTP/1.1" 200 -
2025-08-09 05:47:09,189 - INFO - Loading vector store for context
2025-08-09 05:47:09,190 - INFO - Initializing our Huggingface embedding model
2025-08-09 05:47:09,327 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 05:47:09,328 - INFO - Use pytorch device_name: mps
2025-08-09 05:47:09,328 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 05:47:11,428 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 05:47:11,429 - INFO - Loading existing vectorstore...
2025-08-09 05:47:11,610 - INFO - Loading LLM from HuggingFace
2025-08-09 05:47:11,611 - INFO - LLM loaded sucesfully...
2025-08-09 05:47:11,611 - INFO - Sucesfully created the QA chain
2025-08-09 05:47:11,680 - INFO - 127.0.0.1 - - [09/Aug/2025 05:47:11] "POST / HTTP/1.1" 200 -
2025-08-09 05:50:30,241 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.103:8000
2025-08-09 05:50:30,241 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 05:51:04,468 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.103:5000
2025-08-09 05:51:04,469 - INFO - [33mPress CTRL+C to quit[0m
2025-08-09 05:51:07,292 - INFO - Loading vector store for context
2025-08-09 05:51:07,293 - INFO - Initializing our Huggingface embedding model
2025-08-09 05:51:07,470 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 05:51:11,763 - INFO - Use pytorch device_name: mps
2025-08-09 05:51:11,763 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 05:51:13,631 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 05:51:13,631 - INFO - Loading existing vectorstore...
2025-08-09 05:51:13,635 - INFO - Loading faiss.
2025-08-09 05:51:13,678 - INFO - Successfully loaded faiss.
2025-08-09 05:51:13,681 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-08-09 05:51:13,713 - INFO - Loading LLM from HuggingFace
2025-08-09 05:51:13,772 - INFO - LLM loaded sucesfully...
2025-08-09 05:51:13,772 - INFO - Sucesfully created the QA chain
2025-08-09 05:51:14,123 - INFO - 127.0.0.1 - - [09/Aug/2025 05:51:14] "POST / HTTP/1.1" 200 -
2025-08-09 05:52:03,759 - INFO - Loading vector store for context
2025-08-09 05:52:03,759 - INFO - Initializing our Huggingface embedding model
2025-08-09 05:52:03,877 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-08-09 05:52:03,878 - INFO - Use pytorch device_name: mps
2025-08-09 05:52:03,878 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-08-09 05:52:05,748 - INFO - Huggingface embedding model loaded successfully....
2025-08-09 05:52:05,748 - INFO - Loading existing vectorstore...
2025-08-09 05:52:05,913 - INFO - Loading LLM from HuggingFace
2025-08-09 05:52:05,913 - INFO - LLM loaded sucesfully...
2025-08-09 05:52:05,914 - INFO - Sucesfully created the QA chain
2025-08-09 05:52:05,952 - INFO - 127.0.0.1 - - [09/Aug/2025 05:52:05] "POST / HTTP/1.1" 200 -
